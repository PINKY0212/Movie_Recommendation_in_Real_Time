{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer \nfrom sklearn.metrics.pairwise import linear_kernel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T17:12:56.270854Z","iopub.execute_input":"2022-02-28T17:12:56.271183Z","iopub.status.idle":"2022-02-28T17:12:56.276592Z","shell.execute_reply.started":"2022-02-28T17:12:56.271147Z","shell.execute_reply":"2022-02-28T17:12:56.275610Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:56.279015Z","iopub.execute_input":"2022-02-28T17:12:56.279645Z","iopub.status.idle":"2022-02-28T17:12:56.296444Z","shell.execute_reply.started":"2022-02-28T17:12:56.279576Z","shell.execute_reply":"2022-02-28T17:12:56.295567Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"credits=pd.read_csv('/kaggle/input/tmdb-movie-metadata/tmdb_5000_movies.csv')\nmovies=pd.read_csv('/kaggle/input/tmdb-movie-metadata/tmdb_5000_credits.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:56.297786Z","iopub.execute_input":"2022-02-28T17:12:56.298683Z","iopub.status.idle":"2022-02-28T17:12:56.952948Z","shell.execute_reply.started":"2022-02-28T17:12:56.298621Z","shell.execute_reply":"2022-02-28T17:12:56.952091Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"credits.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:56.954685Z","iopub.execute_input":"2022-02-28T17:12:56.955022Z","iopub.status.idle":"2022-02-28T17:12:56.961551Z","shell.execute_reply.started":"2022-02-28T17:12:56.954975Z","shell.execute_reply":"2022-02-28T17:12:56.960949Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"movies.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:14:01.749379Z","iopub.execute_input":"2022-02-28T17:14:01.749703Z","iopub.status.idle":"2022-02-28T17:14:01.756182Z","shell.execute_reply.started":"2022-02-28T17:14:01.749668Z","shell.execute_reply":"2022-02-28T17:14:01.755164Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"credits.columns = ['id','title','cast','crew'] \nmovies= movies.merge(credits,on='id')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:14:58.190292Z","iopub.execute_input":"2022-02-28T17:14:58.190788Z","iopub.status.idle":"2022-02-28T17:14:58.216521Z","shell.execute_reply.started":"2022-02-28T17:14:58.190745Z","shell.execute_reply":"2022-02-28T17:14:58.215667Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"movies['overview'].head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:57.007501Z","iopub.status.idle":"2022-02-28T17:12:57.010900Z","shell.execute_reply.started":"2022-02-28T17:12:57.010670Z","shell.execute_reply":"2022-02-28T17:12:57.010699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The overview column has a description for each movie. We’ll replace NaN values with empty strings. We’ll be using movie descriptions, the keywords associated with the movie and the genre column to make movie recommendations. Let’s join these columns and make a new column out of it.","metadata":{}},{"cell_type":"code","source":"def create_soup(x): \n    return''.join(x['keywords'])+''+''.join(x['genres'])+''+''.join(x['overview'])\nmovies['soup'] = movies.apply(create_soup, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:57.013466Z","iopub.status.idle":"2022-02-28T17:12:57.014139Z","shell.execute_reply.started":"2022-02-28T17:12:57.013833Z","shell.execute_reply":"2022-02-28T17:12:57.013865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Strings cannot be fed directly into any machine learning algorithm so we will first compute Term Frequency- Inverse Document Frequency.\n\nBefore going any further, let me explain what term frequency is-  it is the relative frequency of any word in a document and is given by dividing term instances with total instances.\n\nThe other part of TF- IDF called Inverse Document Frequency is the relative count of documents containing the term and is given as a log (number of documents/documents with the term).\n\nNow, the overall importance of each word in the document in which they appear would be given by  TF * IDF\n\nThis will give you a matrix where each column represents a word in the overall vocabulary (all the words that appear in at least one document) and each row represents a movie, as before. TF-IDF is useful in reducing the importance of words that occur frequently in our soup of movie description, genre, and keyword and would, in turn, reduce their significance in computing the final similarity score.","metadata":{}},{"cell_type":"markdown","source":"**Creating a TF-IDF Vectorizer**\nFortunately, you won’t have to write the code for all of this ,scikit-learn gives you a built-in TfIdfVectorizer class that you can just call in few lines.","metadata":{}},{"cell_type":"code","source":"tfidf = TfidfVectorizer(stop_words='english')\ntfldf_matrix = tfidf.fit_transform(movies['soup']) \ntfidf_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:57.015860Z","iopub.status.idle":"2022-02-28T17:12:57.016718Z","shell.execute_reply.started":"2022-02-28T17:12:57.016423Z","shell.execute_reply":"2022-02-28T17:12:57.016453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 4803 movies in our dataset are described by over 32768 words. With this tf-idf matrix, we will now compute a similarity score. There are several ways to compute similarity such as- using Euclidean distance  or using the Pearson and the cosine similarity scores. It is good to experiment with them as it cannot be said beforehand which would be best- anyone of these can work based on the scenario.\n\n**Calculating the Cosine Similarity – The Dot Product of Normalized Vectors**\nWe will be using cosine similarity to compute similarity. We use cosine similarity score because it is  independent of magnitude and is also relatively easy and fast to calculate. Mathematically, it could be defined as:\n\n","metadata":{}},{"cell_type":"markdown","source":"Because we are using the TF-IDF vectorizer, computing the dot product will directly give us the cosine similarity score. We are going to use sklearn's linear_kernel() instead of cosine_similarities() as it is faster.","metadata":{}},{"cell_type":"code","source":"cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:57.018030Z","iopub.status.idle":"2022-02-28T17:12:57.018668Z","shell.execute_reply.started":"2022-02-28T17:12:57.018364Z","shell.execute_reply":"2022-02-28T17:12:57.018394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Construct a reverse up of indices and movie titles \nindices = pd.Series(movies.index, index=movies['title']).drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:57.020096Z","iopub.status.idle":"2022-02-28T17:12:57.020555Z","shell.execute_reply.started":"2022-02-28T17:12:57.020306Z","shell.execute_reply":"2022-02-28T17:12:57.020332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Retrieve the index of the movie given its title.\n* Compute a list of cosine similarity scores for our target movie with all movies in the dataset then convert it into a list of tuples where the first element would be is its position and the second is the similarity score.\n* Sort this list of tuples based on similarity scores; which would be the second element.\n* Now, get the top 10 elements of this list. Ignore the first element as it refers to the target movie itself.\n* Return the titles that correspond to the indices of the top elements.","metadata":{}},{"cell_type":"code","source":"def get_recommendations(title,cosine_sim=cosine_sim): \n#Get the index of the movies that matches the title \n idx = indices[title]\n\n# Get the pairwise similarity scores of all movies with that movie \n sim_scores = list(enumerate(cosine_sim[idx]))\n\n#Sort the movies based on the similarity scores \n sim_scores= sorted(sim_scores, key=lambda x: x[1],reverse=True)\n\n#Get the scores of the 10 most similar movies \n sim_scores = sim_scores[1:11]\n\n# Get the movie indices\n movie_indices = [i[0] for i in sim_scores]\n\n# Return the top 10 most similar movies \n return movies['title'].iloc[movie_indices]","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:12:57.021868Z","iopub.status.idle":"2022-02-28T17:12:57.022345Z","shell.execute_reply.started":"2022-02-28T17:12:57.022076Z","shell.execute_reply":"2022-02-28T17:12:57.022102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our recommender has done a good job as it is most likely that Marvel or DC Comic fans would like the movies of the same production house.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}